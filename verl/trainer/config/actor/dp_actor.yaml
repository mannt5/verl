# Format checks enforced on CI:
# 1. Comments must appear above each field.
# 2. There must be a blank line between each field.
# 3. Inline comments (after a field on the same line) are not allowed.
# 4. Indentation level is respected for nested fields.

# defaults specify the default config from each component
defaults:

  # dp actor config, inheriting from trainer/config/actor/actor.yaml
  - actor

  # load the reference default config, then apply the fields in the current yaml
  - _self_

# Target class for this configuration
_target_: verl.workers.config.FSDPActorConfig

# TODO(haibin.lin): switch to fsdp2
strategy: fsdp

# Gradient clipping for actor updates, specific to the strategy.
grad_clip: 1.0

# Sequence parallelism size for Ulysses-style model parallelism
# oc.select: the default val for ref.ulysses_sequence_parallel_size
ulysses_sequence_parallel_size: 1

# calculate entropy with chunking to reduce memory peak
entropy_from_logits_with_chunking: False

# recompute entropy
entropy_checkpointing: False

# optimizer configs
optim:

  # Target class for this configuration
  _target_: verl.workers.config.FSDPOptimizerConfig

  # Minimum LR ratio for cosine schedule
  min_lr_ratio: 0.0

  # Number of cosine cycles in LR schedule
  num_cycles: 0.5

  # LR warmup style: "constant" or "cosine"
  warmup_style: constant

# configs for FSDP
fsdp_config:

  # Target class for this configuration
  _target_: verl.workers.config.FSDPEngineConfig

  # policy for wrapping the model
  wrap_policy:

    # Minimum number of parameters to trigger wrapping a layer with FSDP
    min_num_params: 0

  # Whether to offload model parameters to CPU (trades speed for memory)
  param_offload: false

  # Whether to offload optimizer state to CPU
  optimizer_offload: false

  # Only for FSDP2: offload param/grad/optimizer during train
  offload_policy: false

  # Only for FSDP2: Reshard after forward pass to reduce memory footprint
  reshard_after_forward: true

  # Number of GPUs in each FSDP shard group; -1 means auto
  fsdp_size: -1

  # Only for FSDP1: FSDP1 configuration, prefetch the next forward-pass all-gather
  # before the current forward computation.
  forward_prefetch: False

# Whether to remove padding tokens in inputs during training
use_remove_padding: ${oc.select:actor_rollout_ref.model.use_remove_padding,false}

# profile the actor model in `update_policy` 
profiler:

  # Required when using verl.utils.omega_conf_to_dataclass to instantiate dataclass configs
  _target_: verl.utils.profiler.ProfilerConfig

  # profiler tool, default same as profiler.tool in global config
  # choices: nsys, npu, torch, torch_memory
  tool: ${oc.select:global_profiler.tool,null}

  # whether enable profile on Actor
  enable: False
  
  # Whether to profile all ranks.
  all_ranks: False

  # The ranks that will be profiled. [] or [0,1,...]
  ranks: []

  # profile results saving path
  save_path: ${oc.select:global_profiler.save_path,null}

  # specific tool config which only related to the role
  tool_config:

    # nsys tool config
    nsys:

      # Required when using verl.utils.omega_conf_to_dataclass to instantiate dataclass configs
      _target_: verl.utils.profiler.config.NsightToolConfig
    
      # True for each task has its own database, False for all tasks in one training step share one database.
      discrete: ${oc.select:global_profiler.global_tool_config.nsys.discrete}
    
    # npu config
    npu:

      # Required when using verl.utils.omega_conf_to_dataclass to instantiate dataclass configs
      _target_: verl.utils.profiler.config.NPUToolConfig

      # Contents to profile, can be empty
      # options: npu, cpu, memory, shapes, module, stack
      contents: []

      # Collection level, optional values: level_none, level0, level1, level2.
      level: "level1"

      # Whether to automatically parse the data.
      analysis: True

      # True for each task has its own database, False for all tasks in one training step share one database.
      discrete: False
    
    # torch profiler config
    torch:

      # Required when using verl.utils.omega_conf_to_dataclass to instantiate dataclass configs
      _target_: verl.utils.profiler.config.TorchProfilerToolConfig

      # start profile mini-batch in training
      # NOTICE: different with global steps config which refers to iteration
      # This field only related with mini-batch
      step_start: 0

      # stop profile mini-batch in training
      step_end: null

    # torch memory profiler config
    torch_memory:

      # Required when using verl.utils.omega_conf_to_dataclass to instantiate dataclass configs
      _target_: verl.utils.profiler.config.TorchMemoryToolConfig

      # Maximum number of memory allocation entries to track
      trace_alloc_max_entries: ${oc.select:global_profiler.global_tool_config.torch_memory.trace_alloc_max_entries,100000}

      # Stack trace depth for memory allocations
      stack_depth: ${oc.select:global_profiler.global_tool_config.torch_memory.stack_depth,32}
