{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tags(response):\n",
    "    # Ensure at least one type of tag exists\n",
    "    if '<fact>' not in response and '<commentary>' not in response:\n",
    "        return False\n",
    "    \n",
    "    # Extract all tags in order of appearance\n",
    "    tag_pattern = re.compile(r'<fact>|</fact>|<commentary>|</commentary>')\n",
    "    tags = tag_pattern.findall(response)\n",
    "    \n",
    "    # If no tags found after regex search, validation fails\n",
    "    if not tags:\n",
    "        return False\n",
    "    \n",
    "    # Use stack to check proper nesting and pairing\n",
    "    stack = []\n",
    "    \n",
    "    for tag in tags:\n",
    "        if tag == '<fact>':\n",
    "            # Can't have nested facts or facts inside commentary\n",
    "            if stack and (stack[-1] == '<fact>' or stack[-1] == '<commentary>'):\n",
    "                return False\n",
    "            stack.append(tag)\n",
    "        \n",
    "        elif tag == '</fact>':\n",
    "            # Closing tag must match most recent opening tag\n",
    "            if not stack or stack[-1] != '<fact>':\n",
    "                return False\n",
    "            stack.pop()\n",
    "        \n",
    "        elif tag == '<commentary>':\n",
    "            # Can't have nested commentary or commentary inside facts\n",
    "            if stack and (stack[-1] == '<commentary>' or stack[-1] == '<fact>'):\n",
    "                return False\n",
    "            stack.append(tag)\n",
    "        \n",
    "        elif tag == '</commentary>':\n",
    "            # Closing tag must match most recent opening tag\n",
    "            if not stack or stack[-1] != '<commentary>':\n",
    "                return False\n",
    "            stack.pop()\n",
    "    \n",
    "    # Stack should be empty if all tags are properly paired\n",
    "    return len(stack) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: PASS\n",
      "Test 2: PASS\n",
      "Test 3: PASS\n",
      "Test 4: PASS\n",
      "Test 5: PASS\n",
      "Test 6: PASS\n",
      "Test 7: PASS\n",
      "Test 8: PASS\n",
      "Test 9: PASS\n",
      "Test 10: PASS\n",
      "Test 11: PASS\n",
      "Test 12: PASS\n",
      "Test 13: PASS\n",
      "Test 14: PASS\n",
      "Test 15: PASS\n",
      "Test 16: PASS\n",
      "Test 17: PASS\n",
      "Test 18: PASS\n",
      "Test 19: PASS\n",
      "Test 20: PASS\n",
      "Test 21: PASS\n",
      "Test 22: PASS\n",
      "Test 23: PASS\n",
      "Test 24: PASS\n",
      "All tests completed.\n"
     ]
    }
   ],
   "source": [
    "def test_validate_tags():\n",
    "    # Test cases with expected results\n",
    "    test_cases = [\n",
    "        # Valid cases\n",
    "        (\"<fact>This is a fact.</fact>\", True),\n",
    "        (\"<commentary>This is a commentary.</commentary>\", True),\n",
    "        (\"<fact>Fact 1</fact><commentary>Commentary 1</commentary>\", True),\n",
    "        (\"<commentary>Commentary 1</commentary><fact>Fact 1</fact>\", True),\n",
    "        # TODO: Check if this is something we want to allow (it was part of the original format)\n",
    "        (\"<fact>Fact 1</fact>Some text<commentary>Commentary 1</commentary>\", True),\n",
    "        (\"<fact>Fact 1</fact><fact>Fact 2</fact>\", True),\n",
    "        (\"<commentary>Commentary 1</commentary><commentary>Commentary 2</commentary>\", True),\n",
    "        \n",
    "        # Invalid cases - missing tags\n",
    "        (\"No tags at all\", False),\n",
    "        \n",
    "        # Invalid cases - unbalanced tags\n",
    "        (\"<fact>Unclosed fact\", False),\n",
    "        (\"<fact>Fact 1</fact><fact>Unclosed fact\", False),\n",
    "        (\"</fact>Closing without opening\", False),\n",
    "        (\"<commentary>Unclosed commentary\", False),\n",
    "        (\"</commentary>Closing without opening\", False),\n",
    "        \n",
    "        # Invalid cases - overlapping tags\n",
    "        (\"<fact><commentary>Overlapping</fact></commentary>\", False),\n",
    "        (\"<commentary><fact>Overlapping</commentary></fact>\", False),\n",
    "        \n",
    "        # Invalid cases - nested tags\n",
    "        (\"<fact>Outer <fact>Inner</fact> fact</fact>\", False),\n",
    "        (\"<commentary>Outer <commentary>Inner</commentary> commentary</commentary>\", False),\n",
    "        (\"<fact>Fact with <commentary>nested commentary</commentary></fact>\", False),\n",
    "        (\"<commentary>Commentary with <fact>nested fact</fact></commentary>\", False),\n",
    "        \n",
    "        # Complex cases\n",
    "        (\"<fact>Fact 1</fact><commentary>Commentary 1</commentary><fact>Fact 2</fact>\", True),\n",
    "        (\"<fact>F1</fact>Text<commentary>C1</commentary>Text<fact>F2</fact>Text<commentary>C2</commentary>\", True),\n",
    "        (\"Text<fact>F1</fact>Text<commentary>C1</commentary>Text\", True),\n",
    "        (\"<fact>F1</fact></commentary>Unbalanced closing tag\", False),\n",
    "        (\"<fact>F1</commentary>Wrong closing tag\", False),\n",
    "    ]\n",
    "    \n",
    "    # Run tests\n",
    "    for i, (test_string, expected) in enumerate(test_cases, 1):\n",
    "        result = validate_tags(test_string)\n",
    "        if result == expected:\n",
    "            print(f\"Test {i}: PASS\")\n",
    "        else:\n",
    "            print(f\"Test {i}: FAIL - Expected {expected}, got {result}\")\n",
    "            print(f\"  Input: {test_string}\")\n",
    "    \n",
    "    print(\"All tests completed.\")\n",
    "\n",
    "# Run the test function\n",
    "test_validate_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"/data/synthetic_data/exp/logs/orch_v2_lmunit_serve_1410138.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 22:43:59.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mvLLM version is 0.8.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import re\n",
    "with open(log_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    log_content = f.read()\n",
    "    if \"0.8.3\" in \"0.8.3\":\n",
    "        logger.info(\"vLLM version is 0.8.3\")\n",
    "        if \"Application startup complete\" in log_content:\n",
    "            match = re.search(\n",
    "                r\"Starting server on port:+\\s*(\\d+)\", log_content\n",
    "            )\n",
    "            assert match is not None, \"No match found for vLLM version 0.8.3\"\n",
    "            x =  match.group(1) if match else None\n",
    "\n",
    "        elif \"Uvicorn running on\" in log_content:\n",
    "            match = re.search(\n",
    "                r\"Uvicorn running on http://0\\.0\\.0\\.0:(\\d+)\", log_content\n",
    "            )\n",
    "            assert match is not None, \"No match found for vLLM version 0.8.3\"\n",
    "            x =  match.group(1) if match else None\n",
    "        else:\n",
    "            x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's an a3 node, do not unset NCCL_SOCKET_IFNAME Wed May  7 10:37:09 PM UTC 2025\\nStarting server on port: 50293\\n2025-05-07 22:38:13.425 | INFO     | __main__:initialize_model:31 - Initializing model with checkpoint: /data/wberriosr/checkpoints/al_all_llama3.1_8b_sft_mse_pref.json/lm_1000\\nWARNING 05-07 22:38:51 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\\nNCCL version 2.21.5+cuda12.4\\n\\nLoading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\\n\\nLoading safetensors checkpoint shards:  25% Completed | 1/4 [00:14<00:43, 14.41s/it]\\n\\nLoading safetensors checkpoint shards:  50% Completed | 2/4 [00:16<00:13,  6.89s/it]\\n\\nLoading safetensors checkpoint shards:  75% Completed | 3/4 [00:17<00:04,  4.29s/it]\\n\\nLoading safetensors checkpoint shards: 100% Completed | 4/4 [00:28<00:00,  6.90s/it]\\n\\nLoading safetensors checkpoint shards: 100% Completed | 4/4 [00:28<00:00,  7.03s/it]\\n\\n\\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\\nCapturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:24,  1.38it/s]\\nCapturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:22,  1.44it/s]\\nCapturing CUDA graph shapes:   9%|▊         | 3/35 [00:02<00:21,  1.46it/s]\\nCapturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:21,  1.47it/s]\\nCapturing CUDA graph shapes:  14%|█▍        | 5/35 [00:03<00:20,  1.49it/s]\\nCapturing CUDA graph shapes:  17%|█▋        | 6/35 [00:04<00:19,  1.47it/s]\\nCapturing CUDA graph shapes:  20%|██        | 7/35 [00:04<00:18,  1.49it/s]\\nCapturing CUDA graph shapes:  23%|██▎       | 8/35 [00:05<00:18,  1.49it/s]\\nCapturing CUDA graph shapes:  26%|██▌       | 9/35 [00:06<00:17,  1.49it/s]\\nCapturing CUDA graph shapes:  29%|██▊       | 10/35 [00:06<00:16,  1.51it/s]\\nCapturing CUDA graph shapes:  31%|███▏      | 11/35 [00:07<00:16,  1.47it/s]\\nCapturing CUDA graph shapes:  34%|███▍      | 12/35 [00:08<00:15,  1.45it/s]\\nCapturing CUDA graph shapes:  37%|███▋      | 13/35 [00:08<00:14,  1.48it/s]\\nCapturing CUDA graph shapes:  40%|████      | 14/35 [00:09<00:14,  1.45it/s]\\nCapturing CUDA graph shapes:  43%|████▎     | 15/35 [00:10<00:14,  1.42it/s]\\nCapturing CUDA graph shapes:  46%|████▌     | 16/35 [00:10<00:13,  1.42it/s]\\nCapturing CUDA graph shapes:  49%|████▊     | 17/35 [00:11<00:12,  1.44it/s]\\nCapturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:12<00:11,  1.45it/s]\\nCapturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:13<00:11,  1.44it/s]\\nCapturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:13<00:10,  1.46it/s]\\nCapturing CUDA graph shapes:  60%|██████    | 21/35 [00:14<00:09,  1.47it/s]\\nCapturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:15<00:08,  1.48it/s]\\nCapturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:15<00:08,  1.49it/s]\\nCapturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:16<00:07,  1.51it/s]\\nCapturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:17<00:06,  1.47it/s]\\nCapturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:17<00:06,  1.49it/s]\\nCapturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:18<00:05,  1.51it/s]\\nCapturing CUDA graph shapes:  80%|████████  | 28/35 [00:18<00:04,  1.52it/s]\\nCapturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:19<00:03,  1.52it/s]\\nCapturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:20<00:03,  1.50it/s]\\nCapturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:21<00:02,  1.48it/s]\\nCapturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:21<00:02,  1.43it/s]\\nCapturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:22<00:01,  1.44it/s]\\nCapturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:23<00:00,  1.50it/s]\\nCapturing CUDA graph shapes: 100%|██████████| 35/35 [00:25<00:00,  1.19s/it]\\nCapturing CUDA graph shapes: 100%|██████████| 35/35 [00:25<00:00,  1.37it/s]\\nINFO:     Started server process [398570]\\nINFO:     Waiting for application startup.\\nINFO:     Application startup complete.\\nINFO:     Uvicorn running on http://0.0.0.0:50293 (Press CTRL+C to quit)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbr-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
